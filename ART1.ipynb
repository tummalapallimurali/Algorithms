{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tummalapallimurali/Algorithms/blob/main/ART1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaI8UoJTYKjQ"
      },
      "source": [
        "Problem 3 (software mini-project)\n",
        "\n",
        "Create a file with the first six letters (smaller font – 15 inputs) from project 4.5 on page 215.  These are letters A, B, C, D, E, and J.  Use an encoding with the dots = 0 and the # = 1.  This is a file with 6 pure letters.  Take these six exemplars and create five versions of each exemplar by randomly changing only one bit each.  You now have a new dataset of 30 patterns and six classes. This is a noisier file of patterns.\n",
        "\n",
        "\n",
        "Use the ART1 paradigm to do this problem.  Experiment training with the file with 6 pure letters for five different values of the vigilance parameter and three different values of number of output neurons (this must be set to at least 6 – one for each class).  Then test the trained networks on your training file and on the noisier file.  How did each do?  Then, pick a network that did not do that well, and try complement coding.  Did this change the performance?  Then, pick a network that did pretty well and reorder the training set.  Train again, and see if any differences occurred.  You might try sorting the training patterns from most to least dense (this is supposed to help).  Summarize your results in all these experiments in a table format and discuss your findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYcsf92uYKjU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#Tesing\n",
        "# Step 1: Create the pure letters dataset\n",
        "input_patterns = {\n",
        "    \"A\": [0, 1, 0 ,1, 0 ,1 ,1, 1,1 ,1, 0 ,1 ,1, 0 ,1],\n",
        "    \"B\" : [1,1, 0, 1, 0, 1, 1,1, 0,1,0,1,1,1, 0],\n",
        "    \"C\" :  [1,1, 1, 1, 0, 0,1,0,0,1,0,0,1, 1,1 ],\n",
        "    \"D\" : [1, 1, 0, 1, 0, 1,1, 0, 1,1, 0, 1, 1, 1, 0 ],\n",
        "    \"E\" : [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
        "    \"J\" : [0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0]\n",
        "}\n",
        "\n",
        "\n",
        "# Step 2: Create noisy versions of each letter\n",
        "noisy_input_patterns = {}\n",
        "for letter, pattern in input_patterns.items():\n",
        "    for i in range(1, 6):\n",
        "        noisy_pattern = pattern.copy()\n",
        "        noisy_pattern[np.random.randint(0, len(noisy_pattern))] = 1 - noisy_pattern[np.random.randint(0, len(noisy_pattern))]\n",
        "        noisy_input_patterns[f\"{letter}{i}\"] = noisy_pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV58Dr05YKjW",
        "outputId": "ca3748f3-66ec-4cbe-9b86-dd911120e20d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'A1': [0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1], 'A2': [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1], 'A3': [0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1], 'A4': [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1], 'A5': [1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1], 'B1': [0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0], 'B2': [1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0], 'B3': [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0], 'B4': [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0], 'B5': [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0], 'C1': [0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 'C2': [1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 'C3': [1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 'C4': [1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1], 'C5': [1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], 'D1': [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0], 'D2': [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0], 'D3': [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0], 'D4': [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0], 'D5': [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0], 'E1': [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1], 'E2': [1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1], 'E3': [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0], 'E4': [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1], 'E5': [0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1], 'J1': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0], 'J2': [0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0], 'J3': [0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0], 'J4': [0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0], 'J5': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]}\n"
          ]
        }
      ],
      "source": [
        "print(noisy_input_patterns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlwPOnmDYKjX"
      },
      "source": [
        "Notes: Art1 algorithm(Model developed and tested in numpy and python 3.12) , plese clear outputs and re-run.\n",
        "The following art1 model is implemented in python3. The model is implemented in a class called ART1. The class has the following methods:\n",
        "1. __init__: This is the constructor of the class. It initializes the parameters of the model.\n",
        "2. train: This method trains the model on the input data.\n",
        "3. predict: This method predicts the cluster of the input data. The method returns the cluster number of the input data. The method also returns the vigilance of the model. The vigilance is the minimum similarity between the input data and the cluster prototype.\n",
        "4. The objective of predict method is to identify the cluster of the input data.\n",
        "5. The predict method uses the following formula to calculate the similarity between the input data and the cluster prototype:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER-Nz4XSYKjX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class ART1:\n",
        "    def __init__(self, num_comp, clusters, vigilance, L):\n",
        "        self.num_comp = num_comp\n",
        "        self.clusters = clusters\n",
        "        self.vigilance = vigilance\n",
        "        self.L = L\n",
        "        self.tops = np.ones((clusters, num_comp))\n",
        "        self.bottoms = np.ones((num_comp, clusters)) / (1 + num_comp)\n",
        "        self.assignments = np.zeros(clusters, dtype=int)  # Cluster assignments\n",
        "\n",
        "    # Train the model with the input patterns\n",
        "    def train(self, input_patterns):\n",
        "        for i, (pattern_name, pattern) in enumerate(input_patterns.items()):\n",
        "            pattern = np.array(pattern)\n",
        "            net = np.dot(pattern, self.bottoms)\n",
        "            max_net = np.argmax(net)\n",
        "            vigilance_test = np.dot(pattern, self.tops[max_net]) / np.dot(pattern, pattern)\n",
        "            if vigilance_test >= self.vigilance:\n",
        "                self.tops[max_net] = pattern * self.tops[max_net]\n",
        "                self.bottoms[:, max_net] = (self.L / (self.L - 1 + np.sum(self.tops[max_net]))) * pattern\n",
        "\n",
        "            else:\n",
        "                net[max_net] = -1\n",
        "                max_net = np.argmax(net)\n",
        "                vigilance_test = np.dot(pattern, self.tops[max_net]) / np.dot(pattern, pattern)\n",
        "                if vigilance_test >= self.vigilance:\n",
        "                    self.tops[max_net] = pattern * self.tops[max_net]\n",
        "                    self.bottoms[:, max_net] = (self.L / (self.L - 1 + np.sum(self.tops[max_net]))) * pattern\n",
        "\n",
        "        return self.assignments\n",
        "\n",
        "# Predict the cluster of the input patterns\n",
        "    def predict(self, input_patterns):\n",
        "        data = []\n",
        "        for i, (pattern_name, pattern) in enumerate(input_patterns.items()):\n",
        "            pattern = np.array(pattern)\n",
        "            net = np.dot(pattern, self.bottoms)\n",
        "            max_net = np.argmax(net)\n",
        "            vigilance_test = np.dot(pattern, self.tops[max_net]) / np.dot(pattern, pattern)\n",
        "            if vigilance_test >= self.vigilance:\n",
        "                data.append([pattern_name, max_net])\n",
        "            else:\n",
        "                net[max_net] = -1\n",
        "                max_net = np.argmax(net)\n",
        "                vigilance_test = np.dot(pattern, self.tops[max_net]) / np.dot(pattern, pattern)\n",
        "                if vigilance_test >= self.vigilance:\n",
        "                    data.append([pattern_name, max_net])\n",
        "                else:\n",
        "                    data.append([pattern_name, \"Not assigned\"])\n",
        "        return data\n",
        "\n",
        "\n",
        "    # print weights\n",
        "    def print_weights(self):\n",
        "        print(f\"Top Down Weights: {self.tops}\")\n",
        "        print(f\"Bottom Up Weights: {self.bottoms}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhDy50asYKjY",
        "outputId": "ced8f156-1b82-41b9-905b-44e2e8a6f8b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vigilance: 0.2\n",
            "   Cluster Number     Pattern Name\n",
            "0               0  (A, B, C, D, E)\n",
            "1               1             (J,)\n",
            "\n",
            "\n",
            "\n",
            "Vigilance: 0.3\n",
            "   Cluster Number     Pattern Name\n",
            "0               0  (A, B, C, D, E)\n",
            "1               1             (J,)\n",
            "\n",
            "\n",
            "\n",
            "Vigilance: 0.4\n",
            "   Cluster Number     Pattern Name\n",
            "0               0  (A, B, C, D, E)\n",
            "1               1             (J,)\n",
            "\n",
            "\n",
            "\n",
            "Vigilance: 0.5\n",
            "  Cluster Number  Pattern Name\n",
            "0              0  (A, B, C, D)\n",
            "1              1          (J,)\n",
            "2   Not assigned          (E,)\n",
            "\n",
            "\n",
            "\n",
            "Vigilance: 0.6\n",
            "  Cluster Number Pattern Name\n",
            "0              0    (A, B, D)\n",
            "1              1       (C, E)\n",
            "2   Not assigned         (J,)\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vigilance = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "\n",
        "for v in vigilance:\n",
        "    art1 = ART1(15, 6, v, 2)\n",
        "    art1.train(input_patterns)\n",
        "    data = art1.predict(input_patterns)\n",
        "    # create a dataframe for each vigilance value and print the cluster number and pattern names\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(data, columns=[\"Pattern Name\", \"Cluster Number\"])\n",
        "    print(f\"Vigilance: {v}\")\n",
        "    print(df.groupby(\"Cluster Number\")[\"Pattern Name\"].apply(tuple).reset_index())\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6Gzud5JYKjY"
      },
      "source": [
        "Summary:\n",
        "1. With vigilance parameter 0.2, 0.3 and 0.4 the network was able to cluster patterns A, B, C and D in cluster 0 and\n",
        "J in cluster 1.\n",
        "2. using vigilance parameter 0.5 and 0.6 , it couldnt cluster letter J. Therefore we can use vigilance parameter between 0.2 - 0.3 to fit the patterns.\n",
        "3. when Art1 network is tested on  noisy patterns when predicted letters A1 , A2, A3, A4, A5 .....E5 are predicted in Cluster 0 and J1 - J5 are clustered in 1.\n",
        "4. Updadated weights and printed below. Node 0 and Node 1 weights are updated.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt7jozu-YKjZ",
        "outputId": "e48d0a28-7898-403e-e7b7-3b6e07035878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vigilance: 0.2\n",
            "   Cluster Number                                       Pattern Name\n",
            "0               0  (A1, A2, A3, A4, A5, B1, B2, B3, B4, B5, C1, C...\n",
            "1               1                               (J1, J2, J3, J4, J5)\n",
            "\n",
            "\n",
            "\n",
            "Vigilance: 0.3\n",
            "   Cluster Number                                       Pattern Name\n",
            "0               0  (A1, A2, A3, A4, A5, B1, B2, B3, B4, B5, C1, C...\n",
            "1               1                               (J1, J2, J3, J4, J5)\n",
            "\n",
            "\n",
            "\n",
            "Vigilance: 0.4\n",
            "   Cluster Number                                       Pattern Name\n",
            "0               0  (A1, A2, A3, A4, A5, B1, B2, B3, B4, B5, C1, C...\n",
            "1               1                               (J1, J2, J3, J4, J5)\n",
            "\n",
            "\n",
            "\n",
            "Vigilance: 0.5\n",
            "  Cluster Number                                       Pattern Name\n",
            "0              0  (A1, B1, B3, B4, B5, C1, C2, C3, C4, C5, D2, D...\n",
            "1              1                               (J1, J2, J3, J4, J5)\n",
            "2   Not assigned           (A2, A3, A4, A5, B2, D1, D4, D5, E1, E4)\n",
            "\n",
            "\n",
            "\n",
            "Vigilance: 0.6\n",
            "  Cluster Number                                       Pattern Name\n",
            "0              0  (A1, A2, A3, A4, A5, B1, B2, B3, B4, B5, D1, D...\n",
            "1              1           (C1, C2, C3, C4, C5, E1, E2, E3, E4, E5)\n",
            "2   Not assigned                               (J1, J2, J3, J4, J5)\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vigilance = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "\n",
        "for v in vigilance:\n",
        "    art1 = ART1(15, 6, v, 2)\n",
        "    art1.train(input_patterns)\n",
        "    data = art1.predict(noisy_input_patterns)\n",
        "    # create a dataframe for each vigilance value and print the cluster number and pattern names\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(data, columns=[\"Pattern Name\", \"Cluster Number\"])\n",
        "    print(f\"Vigilance: {v}\")\n",
        "    print(df.groupby(\"Cluster Number\")[\"Pattern Name\"].apply(tuple).reset_index())\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQQ4JxclYKjZ",
        "outputId": "262c43b1-53aa-410a-eb70-ab2285729e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Down Weights: [[0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.]\n",
            " [1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
            "Bottom Up Weights: [[0.25   0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.25   0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.     0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.25   0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.     0.     0.0625 0.0625 0.0625 0.0625]\n",
            " [0.25   0.     0.0625 0.0625 0.0625 0.0625]\n",
            " [0.25   0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.     0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.25   0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.25   0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.     0.     0.0625 0.0625 0.0625 0.0625]\n",
            " [0.25   0.     0.0625 0.0625 0.0625 0.0625]\n",
            " [0.25   0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.25   0.2    0.0625 0.0625 0.0625 0.0625]\n",
            " [0.     0.2    0.0625 0.0625 0.0625 0.0625]]\n"
          ]
        }
      ],
      "source": [
        "# print the weights\n",
        "art1.print_weights()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}